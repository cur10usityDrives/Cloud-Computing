# Deep Learning Pipelines for Apache Spark

## Overview

This project aims to create and evaluate deep learning pipelines using Apache Spark, focusing on leveraging TensorFlow 
for feature extraction and classification. The project involves training a machine learning model to classify images 
using features extracted by a pre-trained InceptionV3 model. We leverage TensorFlow's pre-trained InceptionV3 model to
extract features from images and then apply logistic regression for classification. The project is executed in a Google Colab notebook.

## Features

- **Image Classification**: Utilize TensorFlowâ€™s InceptionV3 model for image feature extraction and classification.
- **Feature Extraction**: Extract and visualize feature maps from images.
- **Model Training**: Train a logistic regression model using extracted features.
- **Prediction and Evaluation**: Predict probabilities for different classes and evaluate model performance.

## Tools

- Python 3.7 or later
- TensorFlow 2.x
- scikit-learn
- pandas
- numpy
- matplotlib

## Usage

The project is implemented in a Google Colab notebook. To use the notebook, follow these steps:

1. Clone this repository:
    ```sh
    git clone https://github.com/cur10usityDrives/Cloud-Computing/new/main/Kubernetes/Machine-
        Learning/Deep-Learning-Pipelines-on-Apache-Spark/deep_learning_pipelines_on_spark.git
    ```
2. Open the `deep_learning_pipelines_on_spark.ipynb` notebook in Google Colab.
3. Run the notebook cells sequentially to execute the code and see the results.

## Author

Natnael Haile
